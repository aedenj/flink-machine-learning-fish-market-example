{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is a record of 7 common different fish species in fish market sales. We want a model to estimate a fish's weight. \n",
    "\n",
    "https://www.kaggle.com/aungpyaeap/fish-market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression performed with an r2 score of `0.965` on the test set while fairly well satisfying the assumptions of an OLS estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn2pmml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import kaggle\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle.api.authenticate()\n",
    "kaggle.api.dataset_download_files('aungpyaeap/fish-market', path='data/', unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Species: Species name of fish\n",
    "* Weight: Weight of fish in gram\n",
    "* Length1: Vertical length in cm\n",
    "* Length2: Diagonal length in cm\n",
    "* Length3: Cross length in cm\n",
    "* Height: Height in cm\n",
    "* Width: Diagonal width in cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/Fish.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we gather basic impressions and answer basic questions abou the data like,\n",
    "\n",
    "* What do some sample values look like?\n",
    "* How many rows are there and what are their types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(frac=.1).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Is there missing data?\n",
    "* Are columns the right types?\n",
    "* Are there outliers in any of the columns? Consider uni-variate and multi-variate analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Is there missing data?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str('Are there any missing values in the dataset?'), data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Are columns the right types?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data['Species'].value_counts()).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the data type displayed in the overview section and the data above that the `Species` columns is categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " data['Species'] = data['Species'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Are there outliers in any of the columns?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Univariate Analysis** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot_fields = ['Weight','Length1','Length2','Length3','Height','Width']\n",
    "fig, ax = plt.subplots(2, 3, figsize=(30, 18))\n",
    "for var, subplot in zip(boxplot_fields, ax.flatten()):\n",
    "    sns.boxplot(x=var, data=data, ax=subplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-Variate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(30, 18))\n",
    "for var, subplot in zip(boxplot_fields, ax.flatten()):\n",
    "    sns.boxplot(x='Species', y=var, data=data, ax=subplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lowerend = 0 # This would otherwise be Q1[c] - (1.5 * IQR[c]) but negative values don't make sense for the variables.\n",
    "upperend = Q3 + (1.5 * IQR)\n",
    "\n",
    "for c in boxplot_fields:\n",
    "    print(c + ':')\n",
    "    upperend = Q3[c] + (1.5 * IQR[c])\n",
    "    feature = data[c]\n",
    "    outliers = feature[(feature <= lowerend) | (feature > upperend)]\n",
    "    print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fishes = data[~((data[boxplot_fields] <= 0) | (data[boxplot_fields] > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "* The outliers that exist per feature in the univariate analysis are not all the same ones that exist in the multivariate analysis by species. So if outliers are identified by a categorical feature that will be in one's model is it often better to remove the overall outliers or those by class of a given categorical feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphical Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributional Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "An early step in any effort to analyze or model data is understanding how the variables are distributed.\n",
    "\n",
    "* What range do the observations cover? \n",
    "* What is their central tendency? \n",
    "* Are they heavily skewed in one direction? \n",
    "* Is there evidence for bimodality? \n",
    "* Are there significant outliers? \n",
    "* Do the answers to these questions vary across subsets defined by other variables?\n",
    "* Is the response variable imbalanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "ax = sns.countplot(x=\"Species\", data=fishes);\n",
    "ax.set_ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "* If the response variable were `Species` then this plot would tell use that we have an imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_for_hist = ['Weight','Length1','Length2','Length3','Height','Width']\n",
    "fig, ax = plt.subplots(2, 3, squeeze=True, figsize=(30, 18))\n",
    "for col, subplot in zip(columns_for_hist, ax.flatten()):\n",
    "    sns.histplot(fishes, x=col, ax=subplot);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "* Length[1,2,3] have nearly identical distributions, which identifies them as probably multicolinear. Thus not all of them should be included in a linear model.\n",
    "* Weight resembles a log normal distribution so transforming that would be worth trying in a our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'll explore correlations. In statistical terms, correlation is a method of assessing a possible two-way linear association between two continuous variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pearson's Correlation**\n",
    "\n",
    "The Pearson product-moment correlation attempts to draw a line of best fit through the data of two variables. The Pearson correlation coefficient, *r*, indicates how far away all these data points are to this line of best fit (i.e., how well the data points fit this new model/line of best fit). The key assumptions of using this statistic are,\n",
    "\n",
    "* Both variables being studied are normally distributed\n",
    "* This coefficient is affected by extreme values, which may exaggerate or dampen the strength of relationship, and is therefore inappropriate when either or both variables are not normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The condition of normal distribution isn't well satisfied from what we can see in the histograms above, but I examine the values for the purposes of understanding our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title(\"Pearson's Correlation\")\n",
    "sns.heatmap(fishes.corr(), annot=True);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "* The response variable, Weight, is highly correlated with all of the other numerical features, which is an indication of high multicolinearity. Although, not definitely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spearmen's Correlation**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key assumptions of using this statistic are,\n",
    "\n",
    "* It is appropriate when one or both variables are skewed or ordinal1 and is robust when extreme values are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.title(\"Spearman's Correlation\")\n",
    "sns.heatmap(fishes.corr(method='spearman'), annot=True);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "* In contrast to Pearson's correlation we see that highest correlation of `Weight` between `Width` and any of `Length[1,2,3]`, but all features show high correlation coefficents. \n",
    "* Features `Length[1,2,3]` are highly colinear "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, I examine the relationships amongst the variables using a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(fishes, kind='scatter', hue='Species');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observations*\n",
    "\n",
    "* There continues to be strong linear relationships between our response variable, `Weight`, and all the features generally.\n",
    "* There are strong linear relationships between `Weight` and each of the features by `Species`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw from Spearmen's correlation and the pair plot above that there are strong linear relationships betweeen `Weight` and serveral of the other variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Statsmodel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "\n",
    "train, test = train_test_split(fishes, test_size=0.3, random_state=1)\n",
    "\n",
    "mod = ols(formula='np.log(Weight) ~ np.log(Width) ', data=train)\n",
    "res = mod.fit()\n",
    "\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following models were also tried, but I found they didn't score as well or violated the assumptions of linear models to a degree that didn't justify their use.\n",
    "* Weight ~ Width\n",
    "* Weight ~ Height * Width * Length1\n",
    "* Weight ~ (Height * Width * Length1) + C(Species)\n",
    "* np.log(Weight) ~ np.log(Height) * np.log(Length1) * np.log(Width) + C(Species)\n",
    "* np.log(Weight) ~ np.log(Height) + np.log(Length1) + np.log(Width) + C(Species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Test Set Performance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(columns=['Weight'])\n",
    "y_test_log = np.log(test['Weight'])\n",
    "y_pred = res.predict(X_test)\n",
    "\n",
    "resids = y_test_log - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.3f' % r2_score(y_test_log, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f' % mean_squared_error(y_test_log, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validate Assumptions of Linear Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Validate Linearity*\n",
    "\n",
    "To detect nonlinearity one can inspect plots of actual vs. predicted values or residuals vs. predicted values. The desired outcome is that points are symmetrically distributed around a diagonal line in the former plot or around a horizontal line in the latter one. In both cases with a roughly constant variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.regplot(x=y_pred, y=y_test_log, lowess=True, line_kws={'color': 'red'})\n",
    "ax.set_title('Actual vs. Predicted Values', fontsize=16)\n",
    "ax.set(xlabel='Predicted', ylabel='Actual');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Residuals Normally Distributed*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The qualtile-quantile (Q-Q) plot provides a handy visual means to inspect the similarity of distributions of a data set. The idea is to plot the quantiles of the sample on the vertical axis and the quantiles of the thoretical distribution on the horizontal axis. If the points of the plot fall on an approximately straight line, you can conclude that the sample distribution is close to the thoretical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "plt.subplots(figsize=(15, 12))\n",
    "ax1 = plt.subplot(221) \n",
    "stats.probplot(resids, plot=ax1)\n",
    "ax1.set_title('Probability Plot', fontsize=16)\n",
    "ax1 = plt.subplot(222) \n",
    "sns.distplot(resids, ax=ax1)\n",
    "ax1.set_title('Distribution of Residuals', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we apply a formal method. The Anderson-Darling test for normal distribution unknown mean and variance. Passing the normality test only allows you to state no significant departure from normality was found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import normal_ad\n",
    "\n",
    "p_value = normal_ad(resids)[1]\n",
    "\n",
    "print('p-value from the test - below 0.05 generally means non-normal:', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*No Multicollinearity Among Predictors*\n",
    "\n",
    "Since we only have one predictor this requirement is not a concern for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*No Autocorrelation of the Error Terms*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "print('\\nPerforming Durbin-Watson Test')\n",
    "print('Values of 1.5 < d < 2.5 generally show that there is no autocorrelation in the data')\n",
    "print('0 to 2< is positive autocorrelation')\n",
    "print('>2 to 4 is negative autocorrelation')\n",
    "print('-------------------------------------')\n",
    "\n",
    "durbinWatson = durbin_watson(resids)\n",
    "print('Durbin-Watson:', durbinWatson)\n",
    "if durbinWatson < 1.5:\n",
    "    print('Signs of positive autocorrelation', '\\n')\n",
    "    print('Assumption not satisfied')\n",
    "elif durbinWatson > 2.5:\n",
    "    print('Signs of negative autocorrelation', '\\n')\n",
    "    print('Assumption not satisfied')\n",
    "else:\n",
    "    print('Little to no autocorrelation', '\\n')\n",
    "    print('Assumption satisfied')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Homoscedasticity*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assumes homoscedasticity, which is the same variance within our error terms. Heteroscedasticity, the violation of homoscedasticity, occurs when we donâ€™t have an even variance across the error terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(x=np.log(X_test['Width']), y=y_test_log, lowess=True, color=\"b\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot clearly shows there's not a uniform variance, but it is better than many of the other models that were list above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Scikit-Learn (using LinearRegression)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we try out the Scikit-Learn implementation in order to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "from sklearn2pmml import sklearn2pmml\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn2pmml.pipeline import PMMLPipeline\n",
    "from sklearn2pmml.decoration import ContinuousDomain\n",
    "from sklearn2pmml.preprocessing import ExpressionTransformer\n",
    "\n",
    "X = fishes.filter(items=['Width'])\n",
    "y = np.log(fishes['Weight'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "mapper = DataFrameMapper([\n",
    "    ([\"Width\"], [ContinuousDomain(), ExpressionTransformer(\"numpy.log(X[0])\", dtype = np.float64)])\n",
    "    #([\"Width\"], [ContinuousDomain(), FunctionTransformer(np.log)])\n",
    "    #(\"Width\", FunctionTransformer(np.log))    \n",
    "])\n",
    "mapper.fit_transform(X)\n",
    "\n",
    "model_pipeline = PMMLPipeline([\n",
    "    (\"mapper\", mapper),\n",
    "    #(\"model\", TransformedTargetRegressor(regressor=LinearRegression(), func=np.log, inverse_func=np.exp))\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "\n",
    "clf = model_pipeline.fit(X_train, y_train);\n",
    "sklearn2pmml(clf, 'fish-weight-model.pmml', with_repr=True, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Test Set Performance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the testing set\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of determination: %.3f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression performed with an r2 score of `0.965` on the test set while fairly well satisfying the assumptions of an OLS estimator."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
